#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import argparse
import time
import os
import sys
import numpy as np
from tqdm import tqdm
import nibabel as nib   
import pandas as pd 
import SimpleITK as sitk
from urllib.request import urlopen

# pytorch 
import torch
import torch.nn 
from torch.utils.data import DataLoader
from torch.optim import lr_scheduler 
from torchvision.transforms import Compose

# TorchIO
import torchio
from torchio import ImagesDataset, Image, Subject, DATA
from torchio.data.sampler import ImageSampler
from torchio.transforms import (    
        ZNormalization,
        RandomMotion, 
        CenterCropOrPad,
        Rescale,    
        RandomNoise,    
        RandomFlip, 
        RandomAffine,   
        ToCanonical,    
        Resample    
    )   

import jstabl
from jstabl.networks.UNetModalityMeanTogether import Generic_UNet
from jstabl.utilities.jaccard import *    
from jstabl.utilities.sampling import GridSampler, GridAggregator 

   
# Define training and patches sampling parameters   
patch_size = (128,128,128)


MODALITIES = ['T1','T1c', 'T2','Flair']


def multi_inference(paths_dict, 
                      model,
                      transformation,
                      device,
                      opt):
    print("[INFO] Loading model.")
    subjects_dataset_inf = ImagesDataset(paths_dict, transform=transformation)

    nb_subject = len(subjects_dataset_inf)

    border = (0,0,0)

    print("[INFO] Starting Inference.")
    for index, batch in enumerate(subjects_dataset_inf):
        original_shape = batch['T1'][DATA].shape[1:]
        name = batch['T1']['stem'].split('T1')[0]
        affine = batch['T1']['affine']
        reference = sitk.ReadImage(opt.t1)

        new_shape = []
        for i,dim in enumerate(original_shape):
            new_dim = dim if dim>patch_size[i] else patch_size[i]
            new_shape.append(new_dim)

        batch_pad = CenterCropOrPad(tuple(new_shape))(batch)
        affine_pad = batch_pad['T1']['affine']


        data = torch.cat([data_mod[DATA] for mod, data_mod in batch_pad.items()],0)
    
        sampler = GridSampler(data, opt.window_size, border)
        aggregator = GridAggregator(data, border)
        loader = DataLoader(sampler, batch_size=1)

        with torch.no_grad():
            for batch_elemt in tqdm(loader):
                locations = batch_elemt['location']
                input_tensor = {'T1':batch_elemt['image'][:,:1,...].to(device)}
                input_tensor['all'] = batch_elemt['image'].to(device)
                labels = 0.0
                for fold in range(1,4):
                    path_model = os.path.join(list(jstabl.__path__)[0], f"./glioma/glioma_{fold}.pth")
                    model.load_state_dict(torch.load(path_model))
                    logits,_ = model(input_tensor)
                    labels+= torch.nn.Softmax(1)(logits)
                labels = labels.argmax(dim=1, keepdim=True)
                outputs = labels
                aggregator.add_batch(outputs, locations)

        output = aggregator.output_array.astype(float)
        output = torchio.utils.nib_to_sitk(output, affine_pad)
        output = sitk.Resample(
            output,
            reference,
            sitk.Transform(),
            sitk.sitkNearestNeighbor,
        )
        sitk.WriteImage(output, opt.output)


def main():
    opt = parsing_data()

    if opt.preprocess:
        try:
            from MRIPreprocessor.mri_preprocessor import Preprocessor
            output_folder = os.path.dirname(opt.output)
            ppr = Preprocessor({
                        'T1':opt.t1,
                        'T2':opt.t2,
                        'T1c':opt.t1c,
                        'Flair':opt.fl},
                        output_folder=output_folder,
                        reference='T1')
            ppr.run_pipeline()
            opt.t1 = os.path.join(output_folder,'skullstripping', 'T1.nii.gz')
            opt.t2 = os.path.join(output_folder,'skullstripping', 'T2.nii.gz')
            opt.t1c = os.path.join(output_folder,'skullstripping', 'T1c.nii.gz')
            opt.fl = os.path.join(output_folder,'skullstripping', 'Flair.nii.gz') 
            
        except ImportError:
            raise ImportError('Please install MRIPreprocessor. Run: ' '\n'
                            '\t pip install  git+https://github.com/ReubenDo/MRIPreprocessor#egg=MRIPreprocessor')

    print("[INFO] Reading data.")
    # Dictionary with data parameters for NiftyNet Reader
    if torch.cuda.is_available():
        print('[INFO] GPU available.')
        device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    else:
        raise Exception(
            "[INFO] No GPU found or Wrong gpu id, please run without --cuda")
   
    # filing paths
    paths_dict = [Subject(
    	Image('T1', opt.t1, torchio.INTENSITY),
    	Image('T1c', opt.t1c, torchio.INTENSITY),
    	Image('T2', opt.t2, torchio.INTENSITY),
    	Image('Flair', opt.fl, torchio.INTENSITY))]
    

    transform_inference = (
            ToCanonical(),
            ZNormalization(),
            Resample(1),      
        )   
    transform_inference = Compose(transform_inference) 
     
    # MODEL 
    norm_op_kwargs = {'eps': 1e-5, 'affine': True}  
    dropout_op_kwargs = {'p': 0, 'inplace': True}   
    net_nonlin = nn.LeakyReLU   
    net_nonlin_kwargs = {'negative_slope': 1e-2, 'inplace': True}   

    print("[INFO] Building model.")  
    model= Generic_UNet(input_modalities=['T1', 'all'],   
                        base_num_features=32,   
                        num_classes=10,     
                        num_pool=4, 
                        num_conv_per_stage=2,   
                        feat_map_mul_on_downscale=2,    
                        conv_op=torch.nn.Conv3d,    
                        norm_op=torch.nn.InstanceNorm3d,    
                        norm_op_kwargs=norm_op_kwargs,  
                        nonlin=net_nonlin,  
                        nonlin_kwargs=net_nonlin_kwargs,      
                        convolutional_pooling=False,     
                        convolutional_upsampling=False,  
                        final_nonlin=lambda x: x,
                        input_features={'T1':1, 'all':4})
    
    for fold in range(1,4):
        path_model = os.path.join(list(jstabl.__path__)[0], f"./glioma/glioma_{fold}.pth")
        if not os.path.isfile(path_model):
            url = f"https://zenodo.org/record/4040853/files/glioma_{fold}.pth?download=1"
            print("Downloading", url, "...")
            data = urlopen(url).read()
            with open(path_model, 'wb') as f:
                f.write(data)

    
    model.to(device)
    model.eval()


    multi_inference(paths_dict, model, transform_inference, device, opt)



def parsing_data():
    parser = argparse.ArgumentParser(
        description='Joint Tissue and Glioma segmentation')


    parser.add_argument('-window_size',
                        type=tuple,
                        default=(112,112,112))

    parser.add_argument('-preprocess',
                        action='store_true', 
                        help='Preprocess includes co-registration and skull-stripping')

    parser.add_argument('-t1',
                        type=str)

    parser.add_argument('-t1c',
                        type=str)

    parser.add_argument('-t2',
                        type=str)

    parser.add_argument('-fl',
                        type=str)

    parser.add_argument('-output',
                        type=str,
                        default='./test_data/output.nii.gz')

    opt = parser.parse_args()

    return opt


if __name__ == '__main__':
    main()



